{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Feature Engineering\n",
    "\n",
    "This notebook presents the execution of the various feature engineering methods that were suggested in the thesis sections 3.3 to 3.5.\n",
    "\n",
    "After loading the preprocessed text from notebook #1, the feature engineering techniques are applied with varying document input sizes (notebook section 3.1). Based on the results, notebook section 3.2 presents an ensemble feature selection approach to construct a robust feature set. After applying the selected TF-IDF 1 method for feature extraction, the features are selected by the Boruta method and the average importance ranking of the remaining feature selection methods. Finally, notebook section 3.2.3 presents the saving of the transformed datasets which are subsequently used for the model building in notebook #4.\n",
    "\n",
    "The results are reported in the thesis section 4.3.1.\n",
    "\n",
    "Table of Contents:\n",
    "* [3.1 Evaluate feature engineering methods over different input sizes](#sizes)\n",
    "    * [3.1.1 Define functions for analysis](#define)\n",
    "    * [3.1.2 Execution of methods](#execution)\n",
    "    * [3.1.3 Print results of analysis](#print)\n",
    "    \n",
    "* [3.2 Ensemble feature selection technique](#ensemble)    \n",
    "    * [3.2.1 TF-IDF 1 text extraction](#extract)\n",
    "    * [3.2.2 Ensemble feature selection](#selection)\n",
    "    * [3.2.3 Saving transformed datasets as pickles](#pickles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading required modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tqdm import tqdm_notebook\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import string\n",
    "import pickle\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from memory_profiler import memory_usage\n",
    "%load_ext memory_profiler\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import statistics \n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "from scipy.stats import rankdata\n",
    "import pytz\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import WordNetLemmatizer, pos_tag, word_tokenize\n",
    "from nltk.corpus.reader.wordnet import WordNetError\n",
    "\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFECV, SelectFromModel\n",
    "\n",
    "import gensim\n",
    "from gensim.sklearn_api import TfIdfTransformer\n",
    "from gensim import corpora\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim import models\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# define functions for loading and saving obejcts\n",
    "def save_pickle(objectname, picklename):\n",
    "    pickle_out = open(picklename,\"wb\") #.pickle\n",
    "    pickle.dump(objectname, pickle_out)\n",
    "    pickle_out.close()\n",
    "    print(picklename, 'successfully pickled.') # e.g. save_pickle(contracts_labeled, 'Pickles/contracts_labeled.pickle')\n",
    "def load_pickle(picklename):\n",
    "    pickle_in = open(picklename,\"rb\")\n",
    "    return pickle.load(pickle_in) # e.g. contracts_labeled = load_pickle('Pickles/contracts_labeled.pickle')\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "# load labels \n",
    "# load data_unlabeled \n",
    " \n",
    "# ensure correct loading\n",
    "print(len(data), len(labels))\n",
    "print(len(data_unlabeled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Evaluate feature engineering methods over different input sizes <a id=\"sizes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 Define functions for analysis <a id=\"define\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the name of object\n",
    "def namestr(obj):\n",
    "    return [name for name in globals() if globals()[name] is obj]\n",
    "\n",
    "# function to retrieve stratified training and validation sample for certain document size\n",
    "def stratified_data(number):\n",
    "    data['Labels'] = labels\n",
    "    data_grouped = data.groupby('Labels', group_keys=False)\n",
    "    \n",
    "    df_stratified = pd.DataFrame(columns = data.columns)\n",
    "    counts = stratified_counts(number) # retrieve absolute number of samples per class (stratified)\n",
    "    if number == len(data):\n",
    "        counts.update({k: round(v* 0.85) for k, v in counts.items()}) #ensure that there is still df_validation if all documents are selected\n",
    "    for i in list(counts.keys()):\n",
    "        amount = counts.get(i)\n",
    "        data_i = data[data['Labels']== i]\n",
    "        df_st = data_i.sample(max(amount, 1))\n",
    "        df_stratified = df_stratified.append(df_st)\n",
    "    \n",
    "    data_updated = data.drop(df_stratified.index.values) # ensure that documents are not selected in both subsets\n",
    "    df_validation = pd.DataFrame(columns = data.columns)\n",
    "    if number == len(data):\n",
    "        df_validation = data_updated #remaining data as validation data\n",
    "    else:      \n",
    "        counts_val = stratified_counts(number*0.15)\n",
    "        for i in list(counts_val.keys()):\n",
    "            amount = counts_val.get(i)\n",
    "            data_iv = data_updated[data_updated['Labels']== i]\n",
    "            df_val = data_iv.sample(max(amount, 1))\n",
    "            df_validation = df_validation.append(df_val)\n",
    "            \n",
    "    return df_stratified, df_validation\n",
    "\n",
    "# function to evaluate absolute number of samples from each class under the condition of stratification\n",
    "def stratified_counts(number):\n",
    "    c = sorted(Counter(labels).items())\n",
    "    percentages = dict((x,y) for x, y in c)\n",
    "    percentages.update({k: v/len(labels) for k, v in percentages.items()})\n",
    "    d = dict((k, round(v*number)) for k, v in percentages.items())\n",
    "    return d\n",
    "\n",
    "# function to define minimum frequency of term in analysis to be included in vectorization\n",
    "def min_df(data, percentage):\n",
    "    min_df_c = len(data) * percentage\n",
    "    return int(round(min_df_c))\n",
    "\n",
    "# function to save folds for consistent usage\n",
    "def folds(data_X, data_y, n):\n",
    "    kf = StratifiedKFold(n_splits=n, shuffle = True, random_state = 42)\n",
    "    trains = list()\n",
    "    valids = list()\n",
    "    for train_ids, valid_ids in kf.split(data_X,  data_y):\n",
    "        trains.append(train_ids)\n",
    "        valids.append(valid_ids)\n",
    "    return trains, valids, kf\n",
    "\n",
    "# function to retrieve the memory usage\n",
    "def get_memory(var):\n",
    "    find_regex = re.compile(r'\\d+.\\d+')\n",
    "    reg = find_regex.search(var)\n",
    "    return float(reg.group()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction using the Bag-of-Words method (thesis section 3.3.1)\n",
    "def bow(column):\n",
    "    data = dataset[column]\n",
    "    count = CountVectorizer(analyzer= 'word', ngram_range = (1, 2), min_df = min_df_c, max_features = None)  \n",
    "    count_vectorizer_best = count.fit(data)\n",
    "    dataset_count = count_vectorizer_best.transform(data)\n",
    "    features = len(count_vectorizer_best.get_feature_names())\n",
    "    validset_count = count_vectorizer_best.transform(validset[column])\n",
    "    return [dataset_count, features, validset_count, count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction using the TF-IDF 1 method (thesis section 3.3.2)\n",
    "def tf_idf_1(column):\n",
    "    data = dataset[column]\n",
    "    tfidf = TfidfVectorizer(analyzer= 'word', ngram_range = (1, 2), min_df = min_df_c, max_features = None, norm = 'l2', smooth_idf = True, sublinear_tf =True)  \n",
    "    tfidf_vectorizer_best = tfidf.fit(data)\n",
    "    dataset_tfidf = tfidf_vectorizer_best.transform(data)\n",
    "    validset_tfidf = tfidf_vectorizer_best.transform(validset[column])\n",
    "    features = len(tfidf_vectorizer_best.get_feature_names())\n",
    "    return [dataset_tfidf, features, validset_tfidf, tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction using the TF-IDF 2 method (thesis section 3.3.2)\n",
    "\n",
    "def tf_idf_2_pivot(data_X, column):\n",
    "    terms_number = list()\n",
    "    for i in range(len(data_X)):\n",
    "        terms_number.append(len(set(data_X[column][i].split())))\n",
    "    return statistics.mean(terms_number)\n",
    "\n",
    "def tf_idf_2(column, avg_pivot, folds_train, folds_valid):\n",
    "    # evaluate the best slope by cross-validation\n",
    "    best_score = 0\n",
    "    token_ = [text.split() for text in dataset[column]]\n",
    "    bigram = Phrases(token_, min_count=min_df_c)\n",
    "    bigram_phraser = Phraser(bigram)\n",
    "    bigram_token = []\n",
    "    for sent in token_:\n",
    "        bigram_token.append(bigram_phraser[sent])\n",
    "    dic = Dictionary(bigram_token)\n",
    "    dic.filter_extremes(no_below = min_df_c)\n",
    "    corpus = [dic.doc2bow(text) for text in bigram_token]\n",
    "    corpus = np.array(corpus)\n",
    "    clf = RandomForestClassifier(n_estimators = 100, n_jobs=-1, random_state = 42, class_weight='balanced')\n",
    "    for slope in np.arange(0, 1.1, 0.1):\n",
    "        tfidf = TfIdfTransformer(normalize = True, smartirs = 'Ltu', pivot = avg_pivot, slope= slope)\n",
    "        scores = list()\n",
    "        for index in range(len(folds_train)):\n",
    "            train_ids = folds_train[index]\n",
    "            valid_ids = folds_valid[index]\n",
    "            cv_clf = deepcopy(clf)\n",
    "            train_X, train_y, valid_X, valid_y = corpus[train_ids], dataset_y[train_ids], corpus[valid_ids], dataset_y[valid_ids]\n",
    "            tfidf_vectorizer = tfidf\n",
    "            tfidf_vectorizer = tfidf_vectorizer.fit(list(train_X))\n",
    "            train_X_tfidf = corpus2csc(tfidf_vectorizer.transform(train_X), num_terms = len(dic)).T\n",
    "            valid_X_tfidf = corpus2csc(tfidf_vectorizer.transform(valid_X), num_terms = len(dic)).T\n",
    "            cv_clf.fit(train_X_tfidf, train_y)\n",
    "            pred = cv_clf.predict(valid_X_tfidf)\n",
    "            scores.append(f1_score(valid_y, pred, average = 'weighted', labels=np.unique(valid_y)))\n",
    "        results = statistics.mean(scores)\n",
    "        if results > best_score:\n",
    "            best_transformer = tfidf # transformer with best slope \n",
    "    \n",
    "    # retrieve tokens from text\n",
    "    token_v = [text.split() for text in validset[column]]\n",
    "    bigram_v = Phrases(token_v) \n",
    "    bigram_phraser_v = Phraser(bigram_v)\n",
    "    bigram_token_v = []\n",
    "    for sent in token_v:\n",
    "        bigram_token_v.append(bigram_phraser_v[sent])\n",
    "    corpus_v = [dic.doc2bow(text) for text in bigram_token_v]\n",
    "    corpus_v = np.array(corpus_v)\n",
    "\n",
    "    # using selected best transformer for final feature extraction\n",
    "    tfidf_best = best_transformer\n",
    "    tfidf_vectorizer_best = tfidf_best.fit(list(corpus))\n",
    "    dataset_tfidf = corpus2csc(tfidf_vectorizer_best.transform(corpus), num_terms = len(dic)).T\n",
    "    validset_tfidf = corpus2csc(tfidf_vectorizer_best.transform(corpus_v), num_terms = len(dic)).T\n",
    "    features = len(dic)\n",
    "    return [dataset_tfidf, features, validset_tfidf, best_transformer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction using the Doc2Vec method (thesis section 3.3.3)\n",
    "\n",
    "def d2v(column):\n",
    "    data = dataset[column]\n",
    "    data_set = [TaggedDocument(sentence.split(), [tag]) for sentence, tag in zip(data, dataset_y)]\n",
    "    valid = validset[column]\n",
    "    \n",
    "    model_dbow = Doc2Vec(data_set, vector_size=500,min_count=min_df_c, dm=0, epchs = 10)\n",
    "    model_dm = Doc2Vec(data_set, vector_size=500,min_count=min_df_c, dm=1, dm_mean=1, epochs = 10)\n",
    "    d2v_model = ConcatenatedDoc2Vec([model_dbow, model_dm]) #concatenating dbow and dm model as recommended in paper\n",
    "\n",
    "    # infer embeddings for data and validation set\n",
    "    predictors_data = []\n",
    "    for sentence in data:\n",
    "        predictor = d2v_model.infer_vector(sentence.split())\n",
    "        predictors_data.append(predictor.tolist())\n",
    "\n",
    "    predictors_valid = []\n",
    "    for sentence in valid:\n",
    "        predictor = d2v_model.infer_vector(sentence.split())\n",
    "        predictors_valid.append(predictor.tolist())\n",
    "    \n",
    "    features = len(predictors_data[0])\n",
    "    return [predictors_data, features, predictors_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature projection using the Principal Component Analysis (thesis section 3.4.1)\n",
    "\n",
    "def PrincipalComponent(data_X, variance_percentage, valid_data):\n",
    "    d = np.array(data_X.todense())\n",
    "    v = np.array(valid_data.todense())\n",
    "    pca = PCA(n_components = variance_percentage, random_state = 42).fit(d)\n",
    "    data_pca = pca.transform(d)\n",
    "    valid_pca = pca.transform(v)\n",
    "    return [data_pca, data_pca.shape[1], valid_pca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature projection using the Linear Discriminant Analysis (thesis section 3.4.2)\n",
    "\n",
    "def LinDisAn(data, variance_percentage, valid):\n",
    "    n_comp = LDA_select_n(data, variance_percentage) # evaluate number of dimensions (see below)\n",
    "    lda = LDA(n_components = n_comp).fit(data, dataset_y)\n",
    "    data_lda = lda.transform(data)\n",
    "    valid_lda = lda.transform(valid)\n",
    "    return data_lda, data_lda.shape[1], valid_lda\n",
    "\n",
    "# retrieve number of dimensions required to achieve the given percentage of explained variance\n",
    "def LDA_select_n(data, goal_var):\n",
    "    lda =  LDA(n_components = None)\n",
    "    features_lda = lda.fit(data, dataset_y)\n",
    "    lda_var_ratios = lda.explained_variance_ratio_\n",
    "    total_variance = 0.0\n",
    "    n_component = 0\n",
    "    for explained_variance in lda_var_ratios: #successively adding a dimension to increase the percentage of explained variance\n",
    "        total_variance += explained_variance\n",
    "        n_component += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "    return n_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using the chi-square test (thesis section 3.5.1)\n",
    "\n",
    "def ChiSquare(data_X, data_y, folds_train, folds_valid, valid):\n",
    "    # evaluate best number of selected features based on cross-validation\n",
    "    best_score = 0\n",
    "    best_n = 0\n",
    "    for n in np.arange(1, data_X.shape[1], round(data_X.shape[1]/20)):\n",
    "        clf = RandomForestClassifier(n_estimators = 100, n_jobs=-1, random_state = 42, class_weight='balanced')\n",
    "        scores = list()\n",
    "        for index in range(len(folds_train)):\n",
    "            train_ids = folds_train[index]\n",
    "            valid_ids = folds_valid[index]\n",
    "            cv_clf = deepcopy(clf)\n",
    "            train_X, train_y, valid_X, valid_y = data_X[train_ids], data_y[train_ids], data_X[valid_ids], data_y[valid_ids]\n",
    "            ch2 = SelectKBest(chi2, k=n)\n",
    "            train_X_chi2 = ch2.fit_transform(train_X, train_y)\n",
    "            valid_X_chi2 = ch2.transform(valid_X)\n",
    "            cv_clf.fit(train_X_chi2, train_y)\n",
    "            score = cv_clf.score(valid_X_chi2, valid_y)\n",
    "            scores.append(score)\n",
    "        result = statistics.mean(scores)\n",
    "        if result > best_score:\n",
    "            best_n = n\n",
    "            best_score = result\n",
    "    #select the 'best_n' features with the highest chi2-statistic and transform the datasets accordingly \n",
    "    ch2 = SelectKBest(chi2, k=best_n).fit(data_X, data_y)\n",
    "    data_CS = ch2.transform(data_X)\n",
    "    valid_CS = ch2.transform(valid)\n",
    "    return [data_CS, data_CS.shape[1], valid_CS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using recursive feature elimination with an underlying default random forest model (thesis section 3.5.2)\n",
    "\n",
    "def RFeatElim(data_X, data_valid, plot = False):\n",
    "    steps = data_X.shape[1]*0.05 # steps in which features will be recursively removed\n",
    "    clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state = 42, class_weight='balanced') # underlying default random forest model\n",
    "    rfecv = RFECV(estimator=clf, step=steps, cv=kf, scoring=make_scorer(f1_score, average=\"weighted\")).fit(data_X, dataset_y)\n",
    "    data_rfe = rfecv.transform(data_X)\n",
    "    valid_rfe = rfecv.transform(data_valid)\n",
    "    return [data_rfe, rfecv.n_features_, valid_rfe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using Boruta with an underlying default random forest model (thesis section 3.5.3)\n",
    "\n",
    "def Boruta(data_X, valid):\n",
    "    rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state = 42, class_weight='balanced') # underlying default random forest model\n",
    "    feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42).fit(data_X.todense(), dataset_y)\n",
    "    data_b = feat_selector.transform(data_X.todense())\n",
    "    data_v = feat_selector.transform(valid.todense())\n",
    "    return [data_b, data_b.shape[1], data_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using random forest selection (thesis section 3.5.4)\n",
    "\n",
    "def RandForS(data_X, valid):\n",
    "    clf = RandomForestClassifier(n_estimators = 100, n_jobs=-1, random_state = 42, class_weight='balanced').fit(data_X, dataset_y) # underlying random forest model\n",
    "    sel = SelectFromModel(clf, prefit = True) # select best features\n",
    "    data_rfs = sel.transform(data_X)\n",
    "    valid_rfs = sel.transform(valid)\n",
    "    return [data_rfs, data_rfs.shape[1], valid_rfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate the transformed datasets using a random forest model\n",
    "def evaluate_data(data_X, data_valid, plot = False):\n",
    "    clf = RandomForestClassifier(n_estimators = 100, n_jobs=-1, random_state = 42, class_weight='balanced')\n",
    "    clf.fit(data_X, dataset_y)\n",
    "    pred = clf.predict(data_valid)\n",
    "    score = f1_score(validset_y, pred, average = 'weighted', labels=np.unique(validset_y))\n",
    "    cm = confusion_matrix(validset_y, pred)\n",
    "    if plot == True:\n",
    "        print(namestr(data_X))\n",
    "        plot_cm(cm)\n",
    "    return score, cm\n",
    "\n",
    "# function to plot the confusion matrix\n",
    "def plot_cm(cm, index, alg):\n",
    "    df_cm = pd.DataFrame(cm, range(len(set(validset_y))), range(len(set(validset_y))))\n",
    "    df_cm.index.name = 'True'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    ax = plt.axes()\n",
    "    sns.set(font_scale=1.4) # for label size\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, ax = ax, fmt='g') # font size\n",
    "    ax.set_title(str(alg)+ ' (' + str(index)+ ' documents)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 Execution of methods <a id=\"execution\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists for saving the several values (score, time, memory etc.) of the different methods over different data sizes\n",
    "start_mem = list()\n",
    "\n",
    "# feature extraction methods\n",
    "bow_scores = list()\n",
    "bow_cm = np.zeros((7, 7))\n",
    "bow_features = list()\n",
    "bow_time = list()\n",
    "bow_mem = list()\n",
    "tfidf1_scores = list()\n",
    "tfidf1_cm = np.zeros((7, 7))\n",
    "tfidf1_features = list()\n",
    "tfidf1_time = list()\n",
    "tfidf1_mem = list()\n",
    "tfidf2_scores = list()\n",
    "tfidf2_cm = np.zeros((7, 7))\n",
    "tfidf2_features = list()\n",
    "tfidf2_time = list()\n",
    "tfidf2_mem = list()\n",
    "d2v_scores = list()\n",
    "d2v_cm = np.zeros((7, 7))\n",
    "d2v_features  = list()\n",
    "d2v_time = list()\n",
    "d2v_mem = list()\n",
    "\n",
    "# feature projection methods\n",
    "pca_scores = list()\n",
    "pca_cm = np.zeros((7, 7))  \n",
    "pca_features = list()\n",
    "pca_time  = list()\n",
    "pca_mem = list()\n",
    "LDAp_scores = list()\n",
    "LDAp_cm = np.zeros((7, 7))  \n",
    "LDAp_features = list()\n",
    "LDAp_time  = list()\n",
    "LDAp_mem = list()\n",
    "\n",
    "# feature selection methods\n",
    "CS_scores = list()\n",
    "CS_cm = np.zeros((7, 7))  \n",
    "CS_features = list()\n",
    "CS_time  = list()\n",
    "CS_mem = list()\n",
    "RFE_scores = list()\n",
    "RFE_cm = np.zeros((7, 7))  \n",
    "RFE_features = list()\n",
    "RFE_time  = list()\n",
    "RFE_mem = list()\n",
    "boruta_scores = list()\n",
    "boruta_cm = np.zeros((7, 7))  \n",
    "boruta_features = list()\n",
    "boruta_time  = list()\n",
    "boruta_mem = list()\n",
    "RFS_scores = list()\n",
    "RFS_cm = np.zeros((7, 7))  \n",
    "RFS_features = list()\n",
    "RFS_time  = list()\n",
    "RFS_mem = list()\n",
    "\n",
    "\n",
    "# number of documents:   [100, 200, 500, 1000, 2500, 5191, 10382, 15574, 20765, 25957] -> [100, 200, 500, 1000, 2500] + [round(int(p * len(data))) for p in [0.2*i for i in range(1,6)]]\n",
    "# number of iterations:  [20   15   10    8     7     6      5     4      3       2]\n",
    "\n",
    "indexes = [25957] * 2 # for example, evaluating the entire labeled corpus\n",
    "for index_docs in tqdm_notebook(indexes, total=len(indexes)):\n",
    "    print(index_docs, 'Dokumente:')\n",
    "    dataset, validset = stratified_data(index_docs) # select stratified data and validation set\n",
    "    dataset_y = labels[list(dataset.index.values)] # select respective data labels\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    validset_y = labels[list(validset.index.values)] # select respective validation labels\n",
    "    validset = validset.reset_index(drop=True)\n",
    "    min_df_c = min_df(dataset, 0.05) # compute minimum absolute frequency that a term must occur to be included -> in 5% of the analysed corpus\n",
    "    folds_train, folds_valid, kf = folds(dataset, dataset_y, 5) # retrieve and save the cross-validation folds to ensure consistency\n",
    "    mst = %memit -o\n",
    "    mem_st = get_memory(str(mst)) #starting memory consumption\n",
    "    start_mem.append(mem_st)\n",
    "    print('Set-Up complete')\n",
    "        \n",
    "    ###############################################################################################################\n",
    "    # Feature Extraction\n",
    "    ## BOW\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    mc = %memit -o bow_data, bow_ft, bow_valid, vect_ca = bow('TEXT_PROCESSED')\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    bow_m = get_memory(str(mc))\n",
    "    bow_mem.append(bow_m)\n",
    "    bow_t = ((end-start).total_seconds())/60\n",
    "    bow_time.append(bow_t)\n",
    "    bow_score, bow_confmat = evaluate_data(bow_data, bow_valid)\n",
    "    bow_scores.append(bow_score)\n",
    "    bow_features.append(bow_ft)\n",
    "    bow_cm += bow_confmat\n",
    "    \n",
    "    ## TF-IDF 1\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))    \n",
    "    mt1 = %memit -o tfidf1_data, tfidf1_ft, tfidf1_valid, vect_sa = tf_idf_1('TEXT_PROCESSED')\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    tfidf1_m = get_memory(str(mt1))\n",
    "    tfidf1_mem.append(tfidf1_m)\n",
    "    tfidf1_t = ((end-start).total_seconds())/60\n",
    "    tfidf1_time.append(tfidf1_t)\n",
    "    tfidf1_score, tfidf1_confmat = evaluate_data(tfidf1_data, tfidf1_valid)\n",
    "    tfidf1_scores.append(tfidf1_score)\n",
    "    tfidf1_features.append(tfidf1_ft)\n",
    "    tfidf1_cm += tfidf1_confmat\n",
    "    \n",
    "    ### TF-IDF 2\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    pivot_tfidf2 = tf_idf_2_pivot(dataset, 'TEXT_PROCESSED')\n",
    "    mt2 = %memit -o tfidf2_data, tfidf2_ft, tfidf2_valid, vect_ga = tf_idf_2('TEXT_PROCESSED', pivot_tfidf2, folds_train, folds_valid)\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    tfidf2_m = get_memory(str(mt2))\n",
    "    tfidf2_mem.append(tfidf2_m)\n",
    "    tfidf2_t = ((end-start).total_seconds())/60\n",
    "    tfidf2_time.append(tfidf2_t)\n",
    "    tfidf2_score, tfidf2_confmat = evaluate_data(tfidf2_data, tfidf2_valid)\n",
    "    tfidf2_scores.append(tfidf2_score)\n",
    "    tfidf2_features.append(tfidf2_ft)\n",
    "    tfidf2_cm += tfidf2_confmat\n",
    "\n",
    "    ## Doc2Vec\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    mda = %memit -o d2v_data, d2v_f, d2v_valid = d2v('TEXT_PROCESSED')\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    d2v_m = get_memory(str(mda))\n",
    "    d2v_mem.append(d2v_m)\n",
    "    d2v_t = ((end-start).total_seconds())/60\n",
    "    d2v_time.append(d2v_t)\n",
    "    d2v_score, d2v_confmat = evaluate_data(d2v_data, d2v_valid)\n",
    "    d2v_scores.append(d2v_score)\n",
    "    d2v_features.append(d2v_f)\n",
    "    d2v_cm += d2v_confmat\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    # Feature decomposition\n",
    "    ## PCA\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    mp = %memit -o data_pca, pca_feature, valid_pca = PrincipalComponent(tfidf1_data, 0.95, tfidf1_valid)\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    pca_m = get_memory(str(mp))\n",
    "    pca_mem.append(pca_m)\n",
    "    pca_t = ((end-start).total_seconds())/60\n",
    "    pca_time.append(pca_t)\n",
    "    pca_s, pca_confmat = evaluate_data(data_pca, valid_pca)\n",
    "    pca_scores.append(pca_s)\n",
    "    pca_features.append(pca_feature)\n",
    "    pca_cm += pca_confmat\n",
    "     \n",
    "    ## LDA (on PCA)\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    mlp = %memit -o data_LDAp, feature_LDAp, valid_LDAp = LinDisAn(data_pca, 0.95, valid_pca)\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    LDAp_m = get_memory(str(mlp))\n",
    "    LDAp_mem.append(LDAp_m)\n",
    "    LDAp_t = ((end-start).total_seconds())/60\n",
    "    LDAp_time.append(LDAp_t)\n",
    "    LDAp_s, LDAc_confmat = evaluate_data(data_LDAp, valid_LDAp)\n",
    "    LDAp_scores.append(LDAp_s)\n",
    "    LDAp_features.append(feature_LDAp)\n",
    "    LDAp_cm += LDAc_confmat \n",
    "    print('Dimensionality Reduction complete')\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # Feature selection\n",
    "    ## Filter methods\n",
    "    ### Chi-Square Test\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    mcs = %memit -o data_CS, feature_CS, valid_CS = ChiSquare(tfidf1_data, dataset_y, folds_train, folds_valid, tfidf1_valid)\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    CS_m = get_memory(str(mcs))\n",
    "    CS_mem.append(CS_m)\n",
    "    CS_t = ((end-start).total_seconds())/60\n",
    "    CS_time.append(CS_t)\n",
    "    CS_s, CS_confmat = evaluate_data(data_CS, valid_CS)\n",
    "    CS_scores.append(CS_s)\n",
    "    CS_features.append(feature_CS)\n",
    "    CS_cm += CS_confmat\n",
    "      \n",
    "    ## Wrapper methods\n",
    "    ### Recursive Feature Elimination\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    mrfe = %memit -o data_RFE, feature_RFE, valid_RFE = RFeatElim(tfidf1_data, tfidf1_valid)\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    RFE_m = get_memory(str(mrfe))\n",
    "    RFE_mem.append(RFE_m)\n",
    "    RFE_t = ((end-start).total_seconds())/60\n",
    "    RFE_time.append(RFE_t)\n",
    "    RFE_s, RFE_confmat = evaluate_data(data_RFE, valid_RFE)\n",
    "    RFE_scores.append(RFE_s)\n",
    "    RFE_features.append(feature_RFE)\n",
    "    RFE_cm += RFE_confmat\n",
    "    \n",
    "    ### Boruta\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    mb = %memit -o data_boruta, feature_boruta, valid_boruta = Boruta(tfidf1_data, tfidf1_valid)\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    boruta_m = get_memory(str(mb))\n",
    "    boruta_mem.append(boruta_m)\n",
    "    boruta_t = ((end-start).total_seconds())/60\n",
    "    boruta_time.append(boruta_t)\n",
    "    boruta_s, boruta_confmat = evaluate_data(data_boruta, valid_boruta)\n",
    "    boruta_scores.append(boruta_s)\n",
    "    boruta_features.append(feature_boruta)\n",
    "    boruta_cm += boruta_confmat\n",
    "    \n",
    "    ## Embedded methods\n",
    "    ### Random Forest Selection\n",
    "    start = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    mrfs = %memit -o data_RFS, feature_RFS, valid_RFS = RandForS(tfidf1_data, tfidf1_valid)\n",
    "    end = datetime.now(pytz.timezone('Europe/Berlin'))\n",
    "    RFS_m = get_memory(str(mrfs))\n",
    "    RFS_mem.append(RFS_m)\n",
    "    RFS_t = ((end-start).total_seconds())/60\n",
    "    RFS_time.append(RFS_t)\n",
    "    RFS_s, RFS_confmat = evaluate_data(data_RFS, valid_RFS)\n",
    "    RFS_scores.append(RFS_s)\n",
    "    RFS_features.append(feature_RFS)\n",
    "    RFS_cm += RFS_confmat\n",
    " \n",
    "    print('Feature Selection complete')\n",
    " \n",
    "    print(\"Time:\", datetime.now(pytz.timezone('Europe/Berlin')).strftime(\"%H:%M:%S\"))\n",
    "    print('----------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3 Print results of analysis <a id=\"print\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results for feature extraction methods\n",
    "\n",
    "t_scores = [bow_scores, tfidf1_scores, tfidf2_scores, d2v_scores]\n",
    "t_features = [bow_features, tfidf1_features, tfidf2_features, d2v_features]\n",
    "t_times = [bow_time, tfidf1_time, tfidf2_time, d2v_time]\n",
    "t_memories = [bow_mem, tfidf1_mem, tfidf2_mem, d2v_mem]\n",
    "confusion_matrixes = [bow_cm, tfidf1_cm, tfidf2_cm, d2v_cm]\n",
    "\n",
    "print(indexes,'\\n')\n",
    "print('Starting memory:', start_mem,'\\n')\n",
    "for i in range(len(t_scores)):\n",
    "    print(namestr(t_scores[i])[0])\n",
    "    print('Score:', t_scores[i])\n",
    "    print('Features:', t_features[i])\n",
    "    print('Time (min):', t_times[i])\n",
    "    print('Memories (Mebibyte; MiB)):', t_memories[i])\n",
    "    print('CMs :', confusion_matrixes[i])\n",
    "    plot_cm(confusion_matrixes[i], indexes[0], namestr(t_scores[i])[0])\n",
    "    print()\n",
    "print('----------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results for feature decomposition methods\n",
    "\n",
    "t_scores_2 = [pca_scores, LDAp_scores, CS_scores, RFE_scores, boruta_scores, RFS_scores]\n",
    "t_features_2 = [pca_features, LDAp_features, CS_features, RFE_features, boruta_features, RFS_features]\n",
    "t_times_2 = [pca_time, LDAp_time, CS_time, RFE_time, boruta_time, RFS_time]\n",
    "t_memories_2 = [pca_mem, LDAp_mem, CS_mem, RFE_mem, boruta_mem, RFS_mem]\n",
    "confusion_matrixes_2 = [pca_cm, LDAp_cm, CS_cm, RFE_cm, boruta_cm, RFS_cm]\n",
    "for i in range(len(t_scores_2)):\n",
    "    print(namestr(t_scores_2[i])[0])\n",
    "    print('Score:', t_scores_2[i])\n",
    "    print('Features:', t_features_2[i])\n",
    "    print('Time (min):', t_times_2[i])\n",
    "    print('Memories (Mebibyte; MiB)):', t_memories_2[i])\n",
    "    print('CMs :', confusion_matrixes_2[i]) # \n",
    "    plot_cm(confusion_matrixes_2[i], indexes[0], namestr(t_scores_2[i])[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Ensemble feature selection technique <a id=\"ensemble\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 TF-IDF 1 transformation <a id=\"extract\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform text into TF-IDF representation\n",
    "labeled_data = data['TEXT_PROCESSED'] #select text\n",
    "unlabeled_data = data_unlabeled['TEXT_PROCESSED'] #select text\n",
    "min_df_c = min_df(labeled_data, 0.05) #compute minimum frequency for term to be included\n",
    "tfidf = TfidfVectorizer(analyzer= 'word', ngram_range = (1, 2), min_df = min_df_c, max_features = None, norm = 'l2', smooth_idf = True, sublinear_tf =True) # initiate uni- and bigram Tf-Idf vectorizer \n",
    "tfidf_vectorizer_best = tfidf.fit(labeled_data) #fit vectorizer on labeled dataset\n",
    "labeled_tfidf = tfidf_vectorizer_best.transform(labeled_data) #transform labeled dataset\n",
    "unlabled_tfidf = tfidf_vectorizer_best.transform(unlabeled_data) #transform unlabeled dataset\n",
    "features = len(tfidf_vectorizer_best.get_feature_names()) #get number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Ensemble Feature Selection based on Boruta & Rankings  <a id=\"selection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boruta feature selection\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state = 42, class_weight='balanced') # underlying default random forest\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42).fit(labeled_tfidf.todense(), labels) # Boruta selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Square feature selection \n",
    "ch2, ch_p = chi2(labeled_tfidf, labels) #calculate chi square statistics for features\n",
    "rnk_cs = rankdata([-1 * i for i in ch2]).astype(int) # rank features according to their importance assessed by chi square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination (RFE)\n",
    "steps = labeled_tfidf.shape[1]*0.05 # determine number of removed feature per iteration\n",
    "kf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42) # ensure stratified cross validation for RFE\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state = 42, class_weight='balanced') # base RFE on random forest model\n",
    "rfecv = RFECV(estimator=clf, step=steps, cv=kf, scoring=make_scorer(f1_score, average=\"weighted\")).fit(labeled_tfidf, labels) # fit RFE on labeled data\n",
    "output_rfe = rfecv.ranking_ # rank features according to their importance assessed by RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Selection (RFS)\n",
    "rfs = RandomForestClassifier(n_estimators = 100, n_jobs=-1, random_state = 42, class_weight='balanced').fit(labeled_tfidf, labels) # fit RFSE on labeled data\n",
    "imp_rfs = rfs.feature_importances_ # feature importances evaluted by RFS\n",
    "rnk_rfs = rankdata([-1 * i for i in imp_rfs]).astype(int) # rank features according to their importance assessed by RFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average rankings (not including the boruta rankings, because their selected features present the basis)\n",
    "all_np = np.array([np.array(rnk_cs), np.array(output_rfe), np.array(rnk_rfs)]) # combine all rankings in one array\n",
    "all_np_avg = list(np.average(all_np, axis=0)) # take average of the 3 rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build labaled and unlabeled dataframes for later filtering \n",
    "df_data = pd.DataFrame(labeled_tfidf.todense(), columns = range(labeled_tfidf.shape[1]))\n",
    "df_uldata = pd.DataFrame(unlabled_tfidf.todense(), columns = range(unlabled_tfidf.shape[1]))\n",
    "\n",
    "# check for shapes of datasets\n",
    "print(df_data.shape)\n",
    "print(df_uldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features based on their ranks\n",
    "\n",
    "bor_data = feat_selector.transform(labeled_tfidf) # labeled dataset containing only the Boruta-selected features\n",
    "b = deepcopy(feat_selector.support_) # Array of selected features: only confirmed ones are True\n",
    "a = np.ma.array(all_np_avg, mask=b) # Array of the average ranks, where the selected Boruta features are masked\n",
    "\n",
    "for i in range(bor_data_df.shape[1]): #loop as often as the number of Boruta features\n",
    "    new_feature = np.argmin(a) #select index of lowest rank\n",
    "    b[new_feature] = True #change entry of selected feature to \"True\" to include it \n",
    "    a = np.ma.array(all_np_avg, mask=b) #update masked array for next round\n",
    "\n",
    "# print controlling number of features \n",
    "print('Desired number of features (dobule boruta features):', bor_data.shape[1]*2)\n",
    "print('Counter of final array with selected features:', dict(Counter(b)))\n",
    "print('Number of features if filtered by the selected ones:', len(b[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter datasets for the selected features\n",
    "labeled_X_final = csc_matrix(df_data[df_data.columns[b]])\n",
    "unlabeled_X_final = csc_matrix(df_uldata[df_uldata.columns[b]])\n",
    "\n",
    "# check for correct transformations of datasets\n",
    "print(labeled_X_final.shape)\n",
    "print(unlabeled_X_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 Saving transformed datasets as pickles <a id=\"pickles\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(labeled_X_final, 'Pickles/2_labeled_X_selected.pickle')\n",
    "save_pickle(unlabeled_X_final, 'Pickles/2_unlabeled_X_selected.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
